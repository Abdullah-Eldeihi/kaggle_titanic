# kaggle_titanic

### The project is about the introductory titanic dataset from Kaggle, it's a classification problem which has 12 columns and around ~900 samples in the training set.
### I began by implementing data cleaning techniques and feature selection then moved onto the EDA part with visualizations, and lastly I tested several models to see which one is the most suitable for this dataset.
#### The models tested were
##### 1: Random Forest
##### 2: KNN
##### 3: Logistic Regression
##### 4: MLP
#### Most models had around 81-83% except MLP which had the highest accuracy which was around ~87% for the validation accuarcy.
